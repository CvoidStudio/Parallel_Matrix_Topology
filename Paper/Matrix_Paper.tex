\documentclass{amsart}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{Property}[theorem]{Property}
\newtheorem{Rule}[theorem]{Rule}
\newtheorem{example}[theorem]{Example}
\newtheorem{xca}[theorem]{Exercise}

\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

\numberwithin{equation}{section}

\newcommand{\abs}[1]{\lvert#1\rvert}

\newcommand{\addpic}[1]{\includegraphics[width=1.0\textwidth]{#1}}
\newcommand{\blankbox}[2]{%
	\parbox{\columnwidth}{\centering
		
		\setlength{\fboxsep}{0pt}%
		\fbox{\raisebox{0pt}[#2]{\hspace{#1}}}%
	}%
}
% Packages
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

\usepackage{amsthm}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{multirow}
\usepackage[
	backend=biber,
	style=ieee,
]{biblatex}
\usepackage{csquotes}
\addbibresource{references.bib}


% Preamble
\title{ANALYSIS OF PARALLEL MATRIX MULTIPLICATION ALGORITHMS}
\author{WENJING CUN, LIHUA PEI, AND YUEFAN DENG}

% --------------------------------------------------------------------------
\begin{document}

	% Title page
	\pagenumbering{gobble}
	\maketitle

	%Abstract
	\begin{abstract}
		
		This paper proposes a general vision onto the construction of the algorithms of parallel matrix multiplication in distributed-memory system. Via the analysis of the communication forest of the algorithms, this paper presents a map of the parallel algorithms for universal matrix multiplication, based on 3-dimensional hypercube algorithm with computational complexity of {O(N^3 )}, and proposes an open problem of promoting the computational complexity in 4-dimensional hypercube. 
		
	\end{abstract}

	% Begin main document



	\section{Introduction}

	High-performance computing (HPC) algorithms of linear operations algebra are critical for many of the computing tasksapplications in engineering and science., Tand to promote the performance of computing in computers, the topology-based algorithms of operations on specific fields are more valuable for research, in order to promote the flexibility and robustness more regardless of the values involved. 
	
	And Aas one of the most essential linear operationsalgebra problems, matrix multiplication is a good start point to launch our research on abstract operation. This paper will mainly discuss about the general method of constructing algorithms for matrix multiplication, and the parallelization of it, with several classical methods as well as analysis of their performances for instance.
	
	In this research, we have discovered a general map to organize the family of the algorithms, and with the metric of parallel efficiency of the lattice, it is now possible for mathematicians to evaluate the upper bound of the algorithms depending on any given dimensions of the matrices, 
	
	Furtherly, this paper proposes a formulated problem to reduce the computational complexity of the algorithm of matrix multiplication, which is still not resolved, yet we will figure it as a future work to research on, to lead the way to optimize the distributed algorithms with computational complexity lower than O(N^3 ).
	
	The organization rest of this manuscriptpaper is organized as the followsing: Section 2 will presents the general idea of designing the algorithms of matrix multiplication on 3D hypercube, based the maps between sets of coordinates. In Section 3, we will propose the problem of describes the construction ofng the communication forest among the computation nodes, while proceeding the parallel algorithms, and organize the family of the parallel algorithms based on 3D hypercube. Then Section 4 will present theperforms analysis of several classical parallel algorithms for matrix multiplication algorithms and proposes an universal matrix multiplication that encapsulates all published algorithms.general algorithm for constructing the distributed plan for universal matrix multiplication. Finally Tthis paper will propose a problem of reducing the computational complexity, and summarize the construction of algorithms. Finally, Section 5 gives the conclusions and outlines the future work.
	
		
	


	\section{CONSTRUCTION OF MATRIX MULTIPLICATION IN 3D HYPERCUBE}
	
	Firstly, we shall review the naïve algorithm of matrix multiplication.
	
	Naïve algorithm is the direct definition of matrix multiplications for any given pair of matrices: A∈R^(m×l),B∈R^(l×n), where m,l and n are some positive integers. And if we just focus on one final result in C=A∙B, namely C_ij, then we have:
	
	Then regardless of the actual values of A_ij and B_jk, formula (1) reveals the information that C_ik only results from the values in the coordinates depending on three indices i,j and k, namely (i,j,k). Then group all (i,j,k) corresponding to the coordinates in A and B together, we may expect there is a well-defined map from such a set of (i,j,k) to that of (i,k) in C.
	
	Sourced from such an idea, and in order to make the algorithms totally independent of the values involved, so that can be flexible and robust, we will define such a map from a set of coordinates to another one in the first subsection.
		
		\subsection{Coordinate Set and Operation Map}
			Maps between sets of values with associate coordinates are often independent of the values involved, but more like the relationship among the indices of coordinates. So to abstract such relationships, we proposed the concept called operation map, of which the definition is as the following:
			\begin{definition}
				An operation map is a map from one set A to another set B, where there are two injective maps L_1:C→A, L_2:C→B, and C is a set with a well-defined operation function τ.
				For convenience, we denote such an operation map f as: f_(C,τ ):A→B, and name L_1,L_2 as the coordinate maps. Here A and B are the topologies from which the sets of values in C abstracted into, and sourcing from the most intuitive concept in geometry, we call A and B the corresponding coordinate sets.
				
				And an abstract operation map has a property sourced from the abstraction of the value set to coordinate sets:
			\end{definition}
			
			\begin{Property}
				Given an operation map f_(G,τ ):C_1→C_2, if S is closed under a well-defined operation τ , or say G is an algebraic group, then for any subset S⊆G, f_(S,τ):C_1→C_2 is also an operation map. Vice Versa.
				
				Such a property shows the stability of an operation map regardless of the values when the inputs in conservative of the algebraic operation. 
				
				For a series of operation maps, they will follow the chain rule if they follow property 2.1:
				
			\end{Property}
			
			\begin{Property}
			Given a set G that is closed under a series of operations τ_1,…,τ_n, a series of sets C_1,…,C_n, also a series of subsets of G, S_1,…,S_n, there exist at least n operation maps:
			(f_1 )_(S_1,τ_1 ),…,(f_n )_(S_n,τ_n )
			
			And (f_1 )_(S_1,τ_1 )°…°(f_n )_(S_n,τ_n )   is also an operation map.
			
			Following the chain rule in the opposite direction, if an abstract operation map f_(G,τ ):C_1→C_2 can be decomposed into a series of abstract operation maps, then we say f_(G,τ) is separable.
			
			The third property we raise here shows one additional great value of abstract operations, that is the flexibility, aka the scalability in computational engineering, if the operation map can be conservative in topology:
			
			\end{Property}
			
			\begin{Property}
			Given two homomorphic algebraic structures G_1 and G_2, closed under two operations τ_1 and τ_2 respectively, if S_1⊆G_1 and S_2⊆G_2 are two subsets, and an operation map f_(S_1,τ_1 ):C_1→C_2, then f_(S_2,τ_2 ):C_1→C_2 is also an operation map.
			
			In the next subsection, we will present the ideas of abstracting the process of matrix multiplication, based on the naïve algorithm 2.1, into a separable operation map composed by several independent stages, and shows the methodology to parallelize the algorithm.
			
			\end{Property}	
		
		\subsection{Algorithms Based on 3-Dimensional Hypercube}
		To abstract the naïve algorithm 3.1 into the operation maps into operations maps mentioned in the previous subsection, the first step is to split all the multiplications between a pair of scalars out, then for the 3D-hypercube algorithm, this step means an abstract operation map from a coordinate set C_11 to the other one C_12. Since the original coordinate set represents the positions of all the entries of A and B, then we denote the set of the coordinate as:
		
		\[
		■(C_A=Z⁄mZ×Z⁄lZ,&C_B=Z⁄lZ×Z⁄nZ)	
		\]
			
		And define the following abstract operation map:
		
		\[
		(2)	(f_1 )_(R,×):C_A×C_B→C_mult3D
		\]
		
		where  C_mult=Z⁄mZ×Z⁄lZ×Z⁄nZ, "×" is the scalar multiplication and:
		
		\[
		(3)	(f_1 )_(R,×) ((r_a,c_a ),(r_b,c_b ))={■((r_a,c_b,c_a )&if  c_a=r_b@∅&ohterwise)┤
		\]
			
		This abstract operation map represents the process: A_ij∙B_jk, and from C_mult, it can be observed that all the mapping can be described as the following figure:
		
		\addpic{figures/ABsideofMatrix}
		
		The next process to be considered is the addition part, here since it is known that only the scalar operation is remained, and the result is a matrix C∈R^(m×n), thus we define the third coordinate set as:
		
		\[
		C_C=Z⁄mZ×Z⁄nZ
		\]
		And the corresponding abstract operation map is defined as:
		
		\[
		(4)	(f_2 )_(R,\+):C_mult3D→C_C}
		\]
		
		\[
		(5)    (f_2 )_(R,+) ((r_a,c_b,c_a ))=(r_a,c_b )
		\]		
		Here "+" is the scalar addition.
		
		 Observed from (4), all the 3D “cubes” in the Figure 2.1 with the same “z-value” are reduced in to one in the “xy-plane”, which can be plotted as the following:
		 
		 \addpic{figures/CsideofMatrix}
		 
		 Now the whole process has been abstracted into a chain of abstract operation maps, for the matrix multiplication operation: F^(m×l)×F^(l×n)→F^(m×n), we can define the chain of abstract operation maps as the following:
		 
		 \[
		 (6)	f_(R^(m×l)×R^(l×n),matrix multiply)=(f_1 )_(R,×)°(f_2 )_(R,+)
		 \]
		 
		 where we define f_(R^(m×l)×R^(l×n),matrix multiply):{1}→{1},  is a trivial abstract operation map directly representing that: C=AB.
		 	
		 For a local-memory system, there seems nothing to modify (5) for such a fixed chain, but to a distributed-memory cluster, we can add one more abstract operation map to each computing node p, g_(R,=), where "=" simply means the identity operation, but can filter the coordinates for each node, and we define it as: 
		 
		 \[
		 (7)	g_(R,=),∶C_mult3D→C_mult3D
		 g_(R,=) ((r_a,c_b,c_a ))={■((r_a,c_b,c_a )&,if (r_a,c_b,c_a )∈U_p@∅&,otherwise),┤
		 \]
		 
		 Here U_p is a custom set chosen for each node p, called a filtering set, represents the “blocks” chosen for node p to calculate. Thus, the chain of abstract operation maps for each node p is written as:
		 
		 \[
		 (8)	(f_p )_(R^(m×l)×R^(l×n),matrix multiply)=(f_1 )_(R,×)°g_(R,=)°(f_2 )_(R,+)
		 \]
		 
		 This formula represents all the value-independent parallel algorithms based on Naïve Algorithm.
		 Now we take such a case for example: if there are totally 4 nodes for computing A∙B, where A∈R^(6×4),B∈R^(4×6), then choose the four filtering sets as:
		 
		 \[
		 (9)	■(U_1={4,5}×{2,3,4}×(Z⁄4Z),&U_2={3}×{2,3,4}×(Z⁄4Z)@U_3={3,4,5}×{0,1}×(Z⁄4Z),&U_4={0,1,2}×{0,1,2,3,4}×(Z⁄4Z) )
		 \]
		 
		 So the “blocks” in C_mult allotted to each node are shown as the following figure:
		 
		 \addpic{figures/Matrix3d_Filter}
		 
		 In fact, the strategy to choose filtering sets as single “cubes” that all span over z-axis, is similar to one of the popular general algorithm for parallel universal matrix multiplication, called BMR[1], if not consider the communication among the nodes. Specially, if the blocks are not finished computing at one communicating step, it can deduce many interesting algorithms, where Cannon’s algorithm[2] and SUMMA[3] are two of the famous ones.
		 
		 So only consider the computational part of the whole process of matrix multiplication, all the algorithms based on naïve algorithm 2.1 can be deduced by selecting the filtering sets {U_p }, so that the algorithm is presented as the following pseudocode:
		 
		 \[
		 Algorithm 2.2:  3D-Hyperblock Matrix Multiplication (A∈R^(m×l),B∈R^(l×n) )
		 if at rank p,
		 Choose U_p   ={(i_1,j_1,k_1 ),(i_2,j_2,k_2 ),…,(i_K,j_K,k_K )}
		 for i,j,k in U_p,
		 C_ik=C_ik+A_ij∙B_jk
		 
		 \]
		 
		 The members in the 3D-Hyperblock family often have the best potential in minimizing the time in communication, however, while dealing with large-scale matrices, the buffer size often becomes a problem for the cluster to limit the total size of data to be deployed onto each computation node. Therefore, each such optimization in communication involves deploying the best subset V_p⊆U_p, and find the best communication tree to pass the data among the nodes, in order to finish the tasks undertaken by U_p efficiently, which is sophisticated while dealing with such P cubes simultaneously.
		 
		 In the next section, we will discuss the influence of limiting buffer size on designing the communication part for a parallel algorithm, and find out a general map for designing the algorithm for parallel matrix multiplication. 
		 
		 
		 
	\section{COMMUNICATION IN 3D-HYPERCUBE}
		Allocation of blocks of operations to each computational node is straightforward for 3D hypercube algorithms, however, while dealing with large-scale matrix multiplications, the restricted buffer size will limit the size of data stored onside each node.
		
		Generally, when a parallel program allows all the nodes to own all the necessary data already, in terms of the algorithm itself, the cost of communication can be minimized. Otherwise, one node lacking necessary data needs to fetch those needed from the other ones. So for parallel matrix multiplication, referring to algorithm 2.2, often we can only deploy part of U_p onto node p, then following the communication tree, at each step, one need to finish as much as computation tasks with its data owing, release or send the data no longer needed, and require and receive the data needed for next step of computation.
		
		\subsection{Communication Rules & Cost}
			For convenience, we describe a “cube” assigned to node p with:
				m_p,l_p,n_p, the lengths of the cube assigned to node p, along with x-axis, y-axis and z-axis respectively;
				
			\addpic{figures/cube}
			
			For many of the algorithms in 3D hypercube family, we may assume that such p communication trees are similar, or out of the geometric vision, such p “cubes” are similar in the following properties:
			
			Volume, i.e. the number of multiplication between entries;
			
			Total projection area onto xz-plane and yz-plane, i.e. the total size of data needed for the computation tasks;
			
			Maximum area projective onto xz-plane and yz-plane can be covered at each communication step, i.e. the maximum buffer size assigned to each core, denoted as Buffer_p.
			
			The three properties above in fact determined the performance of the part of scalar (or even block) multiplication. As for the part of scalar (or even block) addition, there is only one additional property needed to be considered:
			
				Total projection area onto xy-plane, i.e. the size of data to be reduced onto one node.
			Then to design a smart algorithm, we may design following the rules below:
			
			\begin{Rule}
			The total volume of the p cubes is exactly mln, i.e. the total volume of the whole 3D hypercube. i.e. there would be no repetitive computational tasks among the nodes:
			
			\[
			(10)	∑_(p=1)^P▒〖m_p l_p n_p 〗=mln
			\]
			\end{Rule}
			
			\begin{Rule}
		
			The entries of two matrices can be covered by the data stored in the p nodes at each communication step, so that it requires:
			
			\[
			(11)	∑_(p=1)^P▒Buffer_p ≥ml+ln
			\]
			\end{Rule}
		
			\begin{Rule}
				Any entry (or block) stored onside one node can only be released if and only if all the scalar (block) multiplications involving it have been finished. So that the total cost of receiving data on node p is:
				\[
				(12)	T_(p,recv)=C∙(m_p l_p+l_p n_p-Buffer_p )
				\]
			\end{Rule}
		
		From Rule 3.3, since the total number of sending is always conservative with that of receiving, so that we may estimate the average cost of communication on send-receive for each node would follow:

		\[
		(13)	{■(T_(comm,send-recv)≤∑_(p=1)^P▒T_(p,recv) &send/require one by one@T_(comm,send-recv)≥max┬p⁡{T_(p,recv) }&communication parallelized)┤
		\]
		
		where the lower bound comes from the strategy that minimizing the waiting time, where we let the one with the largest demand to send nothing out.
		
		Next, based on the analysis of cost on send-recv, we are going to discuss the strategy of designing the cubes and communication tree for each node.
		
		\subsection{Communication Rules & Cost}
		
		In practical cases, since where all the computation nodes are in the similar conditions (in CPU, GPU, RAM, etc.), we often divide the whole 3D hypercube into P similar (not necessary to be identical) cubes, and assigned with similar limits of buffer sizes.
		
		For each cube assigned to each node, due to the restriction to buffer size, our communication objective is:
		
		Numerate U_p={(x_pi,y_pi,z_pi )} by taking the operation map (3) mentioned in section 2.1, which is source from A_pk×B_pk at each communication step  k, where it should satisfy that:
		
		\[
		(14)	|C_pAk |+|C_pBk |≤〖Buffer〗_p
		\]
		
		So that we can see, to parallelize the matrix multiplication by adding the communication part in 3D hypercube, the form of the operation maps can be totally conserved, and so construct a union of a series of operation maps in the same forms:
		
		\[
		(15)	(f_p1 )_(R,×):C_pA×C_pB→C_(p,mult3D) □(⇒┴parallelized ) C_(p,mult3D)=⋃_(k=1)^(total steps K)▒C_(p,mult3D,k) =⋃_(k=1)^K▒〖C_pAk×C_pBk 〗
		\]
		
		Now to minimize the communication cost on each node with fixed limit of buffer size, we want to prove that:
		\begin{Theorem 3.1}
			To numerate U_p={(x_pi,y_pi,z_pi )}, for {C_pAk } and {C_pBk } satisfying (14), there can exist {C_pAk } and {C_pBk } so that:
			\[
			For ∆k>1, d∈C_pAk∩C_(pA,(k+∆k) ) only if d∈C_pAk∩C_(pA,(k+∆k-1) );
			For ∆k>1, d∈C_pBk∩C_(pB,(k+∆k) ) only if d∈C_pBk∩C_(pB,(k+∆k-1) );
			
			\]
			
			if given that 〖Buffer〗_p≥min⁡{m_p,n_p }.
			
			This theorem states the availability of Rule 3.3, so that no data (entry or block) would be sent to any one node redundantly. And the given condition can propose a general strategy for send-receive and so prove the existence.

			This strategy with the condition 〖Buffer〗_p≥min⁡{m_p,n_p } can be stated as the following:
			
			\[
			Algorithm 3.1:  3D-Hyperblock Algorithm with Communication
			(m_p,l_p,n_p,Buffer_p∈N^+,m_p≤n_p )
			
			if at rank p,
			Choose U_p   ={(i_1,j_1,k_1 ),(i_2,j_2,k_2 ),…,(i_K,j_K,k_K )}=(Z_(m_p )×Z_(l_p )×Z_(n_p ) )⨁(i_low,j_low,k_low ),
			Let C_pA=(Z_(m_p )×Z_(l_p ) )⨁(i_low,j_low ) and C_pB=(Z_(l_p )×Z_(n_p ) )⨁(j_low,k_low ).
			Sort U_p, C_pA and C_pB increasingly with j.
			Let  〖StepSize〗_A = ⌊Buffer_p⁄m_p ⌋.
			And initialize the buffer as:
			■(C_(pA,0)=C_pA [0:〖StepSize〗_A ],&C_(pB,0)=C_pB [0:〖Buffer_p-StepSize〗_A ] )
			Set numbers of steps associated to two sets as k_A=k_B=0.
			
			for i,j,k in U_p,
			if (i,j)∈C_(pA,k_A ) and (j,k)∈C_(pB,k_B ):
			C_ik=C_ik+A_ij∙B_jk
			ready to send (i,j)∈C_(pA,k_A ) and (j,k)∈C_(pB,k_B )
			else if (j,k)∉C_(pB,k_B ):
			require (j,k) from another node
			pop the front of C_(pB,k_B )
			push (j,k) into the back of C_(pB,k_B )
			k_B=k_B+1
			else if (i,j)∉C_(pA,k_A ):
			require (j,k) from another node
			pop the front of C_(pA,k_A )
			push (i,j) into the back of C_(pA,k_A )
			k_A=k_A+1 
			
			\]
			
			This algorithm designs a communication tree for each node, with which we can construct an algorithm with only the following two given conditions:
			
			m_p,l_p,n_p, i.e. a cube assigned to each node p;
			
			Buffer_p
			
			And the algorithm designed based on algorithm 3.1 is called the Buffer Adaptive Matrix Multiplication Algorithm (BAMMA), which can fit to pair of matrices with random dimensions and make the best usage of buffer onside each node.
			Next we will evaluate the performance of BAMMA, based on the variables raised in section 3.1, and show the general prediction of parallel efficiency of the algorithms for parallel matrix multiplication in 3D Hypercube family.
			
			\subsection{Performance Analysis}
			
			


\end{document}
